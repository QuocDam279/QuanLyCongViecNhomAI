// backend/services/ai-service/services/llmService.js
const axios = require('axios');

exports.askLLM = async (query, context) => {
  const prompt = `
C√¢u h·ªèi: ${query}

üìÑ T√†i li·ªáu:
${context.documents?.length
  ? context.documents.map(doc => `- ${doc.title}: ${doc.summary || ''}`).join('\n')
  : 'Kh√¥ng c√≥ t√†i li·ªáu n√†o.'}

üìä Ho·∫°t ƒë·ªông nh√≥m:
${context.activities?.length
  ? context.activities.map(act => `- ${act.description} (${act.timestamp})`).join('\n')
  : 'Kh√¥ng c√≥ ho·∫°t ƒë·ªông n√†o.'}

üìà Ti·∫øn ƒë·ªô nh√≥m:
${context.mcp ? JSON.stringify(context.mcp, null, 2) : 'Ch∆∞a c√≥ d·ªØ li·ªáu ti·∫øn ƒë·ªô.'}
`;

  try {
    const response = await axios.post(
      process.env.LLM_ENDPOINT,
      {
        model: process.env.LLM_MODEL || 'mistralai/mistral-7b-instruct',
        messages: [
          { role: 'user', content: prompt }
        ]
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    const choices = response.data?.choices;
    if (choices && choices.length > 0 && choices[0].message?.content) {
      return choices[0].message.content;
    } else {
      console.warn('‚ö†Ô∏è Model kh√¥ng tr·∫£ v·ªÅ n·ªôi dung h·ª£p l·ªá:', response.data);
      return 'Xin l·ªói, t√¥i ch∆∞a th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y.';
    }
  } catch (err) {
    console.error('‚ùå L·ªói g·ªçi model qua OpenRouter:', err.message, err.response?.data || '');
    return 'Xin l·ªói, t√¥i ch∆∞a th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y.';
  }
};